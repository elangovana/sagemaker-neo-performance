{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression with Amazon SageMaker XGBoost algorithm\n",
    "_**Single machine training for regression with Amazon SageMaker XGBoost algorithm**_\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "## Contents\n",
    "1. [Introduction](#Introduction)\n",
    "2. [Setup](#Setup)\n",
    "  1. [Fetching the dataset](#Fetching-the-dataset)\n",
    "  2. [Data Ingestion](#Data-ingestion)\n",
    "3. [Training the XGBoost model](#Training-the-XGBoost-model)\n",
    "  1. [Plotting evaluation metrics](#Plotting-evaluation-metrics)\n",
    "4. [Set up hosting for the model](#Set-up-hosting-for-the-model)\n",
    "  1. [Import model into hosting](#Import-model-into-hosting)\n",
    "  2. [Create endpoint configuration](#Create-endpoint-configuration)\n",
    "  3. [Create endpoint](#Create-endpoint)\n",
    "5. [Validate the model for use](#Validate-the-model-for-use)\n",
    "\n",
    "---\n",
    "## Introduction\n",
    "\n",
    "This notebook demonstrates the use of Amazon SageMaker’s implementation of the XGBoost algorithm to train and host a regression model. We use the [Abalone data](https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/regression.html) originally from the [UCI data repository](https://archive.ics.uci.edu/ml/datasets/abalone). More details about the original dataset can be found [here](https://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.names).  In the libsvm converted [version](https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/regression.html), the nominal feature (Male/Female/Infant) has been converted into a real valued feature. Age of abalone is to be predicted from eight physical measurements.  \n",
    "\n",
    "---\n",
    "## Setup\n",
    "\n",
    "\n",
    "This notebook was created and tested on an ml.m4.4xlarge notebook instance.\n",
    "\n",
    "Let's start by specifying:\n",
    "1. The S3 bucket and prefix that you want to use for training and model data. This should be within the same region as the Notebook Instance, training, and hosting.\n",
    "1. The IAM role arn used to give training and hosting access to your data. See the documentation for how to create these. Note, if more than one role is required for notebook instances, training, and/or hosting, please replace the boto regexp with a the appropriate full IAM role arn string(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "isConfigCell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 703 ms, sys: 291 ms, total: 995 ms\n",
      "Wall time: 731 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import os\n",
    "import boto3\n",
    "import re\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "bucket='aegovansagemaker' # put your s3 bucket name here, and create s3 bucket\n",
    "prefix = 'sagemaker/DEMO-xgboost-regression'\n",
    "# customize to your bucket where you have stored the data\n",
    "bucket_path = 'https://s3-{}.amazonaws.com/{}'.format(region,bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching the dataset\n",
    "\n",
    "Following methods split the data into train/test/validation datasets and upload files to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6 µs, sys: 1e+03 ns, total: 7 µs\n",
      "Wall time: 9.78 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import io\n",
    "import boto3\n",
    "import random\n",
    "\n",
    "def data_split(FILE_DATA, FILE_TRAIN, FILE_VALIDATION, FILE_TEST, PERCENT_TRAIN, PERCENT_VALIDATION, PERCENT_TEST):\n",
    "    data = [l for l in open(FILE_DATA, 'r')]\n",
    "    train_file = open(FILE_TRAIN, 'w')\n",
    "    valid_file = open(FILE_VALIDATION, 'w')\n",
    "    tests_file = open(FILE_TEST, 'w')\n",
    "\n",
    "    num_of_data = len(data)\n",
    "    num_train = int((PERCENT_TRAIN/100.0)*num_of_data)\n",
    "    num_valid = int((PERCENT_VALIDATION/100.0)*num_of_data)\n",
    "    num_tests = int((PERCENT_TEST/100.0)*num_of_data)\n",
    "\n",
    "    data_fractions = [num_train, num_valid, num_tests]\n",
    "    split_data = [[],[],[]]\n",
    "\n",
    "    rand_data_ind = 0\n",
    "\n",
    "    for split_ind, fraction in enumerate(data_fractions):\n",
    "        for i in range(fraction):\n",
    "            rand_data_ind = random.randint(0, len(data)-1)\n",
    "            split_data[split_ind].append(data[rand_data_ind])\n",
    "            data.pop(rand_data_ind)\n",
    "\n",
    "    for l in split_data[0]:\n",
    "        train_file.write(l)\n",
    "\n",
    "    for l in split_data[1]:\n",
    "        valid_file.write(l)\n",
    "\n",
    "    for l in split_data[2]:\n",
    "        tests_file.write(l)\n",
    "\n",
    "    train_file.close()\n",
    "    valid_file.close()\n",
    "    tests_file.close()\n",
    "\n",
    "def write_to_s3(fobj, bucket, key):\n",
    "    return boto3.Session(region_name=region).resource('s3').Bucket(bucket).Object(key).upload_fileobj(fobj)\n",
    "\n",
    "def upload_to_s3(bucket, channel, filename):\n",
    "    fobj=open(filename, 'rb')\n",
    "    key = prefix+'/'+channel\n",
    "    url = 's3://{}/{}/{}'.format(bucket, key, filename)\n",
    "    print('Writing to {}'.format(url))\n",
    "    write_to_s3(fobj, bucket, key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data ingestion\n",
    "\n",
    "Next, we read the dataset from the existing repository into memory, for preprocessing prior to training. This processing could be done *in situ* by Amazon Athena, Apache Spark in Amazon EMR, Amazon Redshift, etc., assuming the dataset is present in the appropriate location. Then, the next step would be to transfer the data to S3 for use in training. For small datasets, such as this one, reading into memory isn't onerous, though it would be for larger datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to s3://aegovansagemaker/sagemaker/DEMO-xgboost-regression/train/abalone.train\n",
      "Writing to s3://aegovansagemaker/sagemaker/DEMO-xgboost-regression/validation/abalone.validation\n",
      "Writing to s3://aegovansagemaker/sagemaker/DEMO-xgboost-regression/test/abalone.test\n",
      "CPU times: user 154 ms, sys: 25.8 ms, total: 180 ms\n",
      "Wall time: 3.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import urllib.request\n",
    "\n",
    "# Load the dataset\n",
    "FILE_DATA = 'abalone'\n",
    "urllib.request.urlretrieve(\"https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/regression/abalone\", FILE_DATA)\n",
    "\n",
    "#split the downloaded data into train/test/validation files\n",
    "FILE_TRAIN = 'abalone.train'\n",
    "FILE_VALIDATION = 'abalone.validation'\n",
    "FILE_TEST = 'abalone.test'\n",
    "PERCENT_TRAIN = 70\n",
    "PERCENT_VALIDATION = 15\n",
    "PERCENT_TEST = 15\n",
    "data_split(FILE_DATA, FILE_TRAIN, FILE_VALIDATION, FILE_TEST, PERCENT_TRAIN, PERCENT_VALIDATION, PERCENT_TEST)\n",
    "\n",
    "#upload the files to the S3 bucket\n",
    "upload_to_s3(bucket, 'train', FILE_TRAIN)\n",
    "upload_to_s3(bucket, 'validation', FILE_VALIDATION)\n",
    "upload_to_s3(bucket, 'test', FILE_TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = sklearn.datasets.load_svmlight_file(FILE_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(x.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0      1      2      3       4       5       6     7\n",
       "0  1.0  0.455  0.365  0.095  0.5140  0.2245  0.1010  0.15\n",
       "1  1.0  0.350  0.265  0.090  0.2255  0.0995  0.0485  0.07\n",
       "2  2.0  0.530  0.420  0.135  0.6770  0.2565  0.1415  0.21"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the XGBoost model\n",
    "\n",
    "After setting training parameters, we kick off training, and poll for status until training is completed, which in this example, takes between 5 and 6 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "container = get_image_uri(region, 'xgboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training job DEMO-xgboost-regression-2019-04-01-15-59-34\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "Completed\n",
      "CPU times: user 72.3 ms, sys: 11 ms, total: 83.3 ms\n",
      "Wall time: 3min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import boto3\n",
    "from time import gmtime, strftime\n",
    "\n",
    "job_name = 'DEMO-xgboost-regression-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(\"Training job\", job_name)\n",
    "\n",
    "#Ensure that the training and validation data folders generated above are reflected in the \"InputDataConfig\" parameter below.\n",
    "\n",
    "create_training_params = \\\n",
    "{\n",
    "    \"AlgorithmSpecification\": {\n",
    "        \"TrainingImage\": container,\n",
    "        \"TrainingInputMode\": \"File\"\n",
    "    },\n",
    "    \"RoleArn\": role,\n",
    "    \"OutputDataConfig\": {\n",
    "        \"S3OutputPath\": bucket_path + \"/\" + prefix + \"/single-xgboost\"\n",
    "    },\n",
    "    \"ResourceConfig\": {\n",
    "        \"InstanceCount\": 1,\n",
    "        \"InstanceType\": \"ml.m4.4xlarge\",\n",
    "        \"VolumeSizeInGB\": 5\n",
    "    },\n",
    "    \"TrainingJobName\": job_name,\n",
    "    \"HyperParameters\": {\n",
    "        \"max_depth\":\"5\",\n",
    "        \"eta\":\"0.2\",\n",
    "        \"gamma\":\"4\",\n",
    "        \"min_child_weight\":\"6\",\n",
    "        \"subsample\":\"0.7\",\n",
    "        \"silent\":\"0\",\n",
    "        \"objective\":\"reg:linear\",\n",
    "        \"num_round\":\"50\"\n",
    "    },\n",
    "    \"StoppingCondition\": {\n",
    "        \"MaxRuntimeInSeconds\": 3600\n",
    "    },\n",
    "    \"InputDataConfig\": [\n",
    "        {\n",
    "            \"ChannelName\": \"train\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": bucket_path + \"/\" + prefix + '/train',\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\"\n",
    "                }\n",
    "            },\n",
    "            \"ContentType\": \"libsvm\",\n",
    "            \"CompressionType\": \"None\"\n",
    "        },\n",
    "        {\n",
    "            \"ChannelName\": \"validation\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": bucket_path + \"/\" + prefix + '/validation',\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\"\n",
    "                }\n",
    "            },\n",
    "            \"ContentType\": \"libsvm\",\n",
    "            \"CompressionType\": \"None\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "client = boto3.client('sagemaker', region_name=region)\n",
    "client.create_training_job(**create_training_params)\n",
    "\n",
    "import time\n",
    "\n",
    "status = client.describe_training_job(TrainingJobName=job_name)['TrainingJobStatus']\n",
    "print(status)\n",
    "while status !='Completed' and status!='Failed':\n",
    "    time.sleep(60)\n",
    "    status = client.describe_training_job(TrainingJobName=job_name)['TrainingJobStatus']\n",
    "    print(status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the \"validation\" channel has been initialized too. The SageMaker XGBoost algorithm actually calculates RMSE and writes it to the CloudWatch logs on the data passed to the \"validation\" channel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting evaluation metrics\n",
    "Evaluation metrics for the completed training job are available in CloudWatch. We can pull the area under curve metric for the validation data set and plot it to see the performance of the model over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from sagemaker.analytics import TrainingJobAnalytics\n",
    "\n",
    "metric_name = 'validation:rmse'\n",
    "\n",
    "metrics_dataframe = TrainingJobAnalytics(training_job_name=job_name, metric_names=[metric_name]).dataframe()\n",
    "plt = metrics_dataframe.plot(kind='line', figsize=(12,5), x='timestamp', y='value', style='b.', legend=False)\n",
    "plt.set_ylabel(metric_name);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up hosting for the model\n",
    "In order to set up hosting, we have to import the model from training to hosting. \n",
    "\n",
    "### Import model into hosting\n",
    "\n",
    "Register the model with hosting. This allows the flexibility of importing models trained elsewhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEMO-xgboost-regression-2019-04-01-15-59-34-model\n"
     ]
    }
   ],
   "source": [
    "model_name=job_name + '-model'\n",
    "print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEMO-xgboost-regression-2019-04-01-15-59-34-model\n",
      "https://s3-us-east-2.amazonaws.com/aegovansagemaker/sagemaker/DEMO-xgboost-regression/single-xgboost/DEMO-xgboost-regression-2019-04-01-15-59-34/output/model.tar.gz\n",
      "arn:aws:sagemaker:us-east-2:324346001917:model/demo-xgboost-regression-2019-04-01-15-59-34-model\n",
      "CPU times: user 14.9 ms, sys: 992 µs, total: 15.8 ms\n",
      "Wall time: 271 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import boto3\n",
    "from time import gmtime, strftime\n",
    "\n",
    "\n",
    "\n",
    "info = client.describe_training_job(TrainingJobName=job_name)\n",
    "model_data = info['ModelArtifacts']['S3ModelArtifacts']\n",
    "print(model_data)\n",
    "\n",
    "primary_container = {\n",
    "    'Image': container,\n",
    "    'ModelDataUrl': model_data\n",
    "}\n",
    "\n",
    "create_model_response = client.create_model(\n",
    "    ModelName = model_name,\n",
    "    ExecutionRoleArn = role,\n",
    "    PrimaryContainer = primary_container)\n",
    "\n",
    "print(create_model_response['ModelArn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neo\n",
    "Compile into neo and host it on exactly the same instance as the regular XGBoost Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = 's3://{}/{}/{}'.format(bucket, prefix, \"neo\")\n",
    "model_S3 =   \"s3://{}\".format(\"/\".join(model_data.split(\"/\")[3:]))\n",
    "\n",
    "compilation_job_name = 'string'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = client.create_compilation_job(\n",
    "    CompilationJobName=compilation_job_name,\n",
    "    RoleArn=role,\n",
    "    InputConfig={\n",
    "        'S3Uri': model_S3,\n",
    "        'DataInputConfig':'[10]',\n",
    "        'Framework': 'XGBOOST'\n",
    "    },\n",
    "    OutputConfig={\n",
    "        'S3OutputLocation': output_path,\n",
    "        'TargetDevice': 'ml_m4'\n",
    "    },\n",
    "    StoppingCondition={\n",
    "        'MaxRuntimeInSeconds': 123\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CompilationJobArn': 'arn:aws:sagemaker:us-east-2:324346001917:compilation-job/string',\n",
       " 'ResponseMetadata': {'RequestId': '851eb3c7-88d1-465f-82bc-e9ea96198b9e',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '851eb3c7-88d1-465f-82bc-e9ea96198b9e',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '87',\n",
       "   'date': 'Mon, 01 Apr 2019 16:23:28 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the model into Neo runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "string-neo-model-latest\n",
      "s3://aegovansagemaker/sagemaker/DEMO-xgboost-regression/neo/model-ml_m4.tar.gz\n",
      "arn:aws:sagemaker:us-east-2:324346001917:model/string-neo-model-latest\n",
      "CPU times: user 5.55 ms, sys: 10.2 ms, total: 15.8 ms\n",
      "Wall time: 466 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import boto3\n",
    "from time import gmtime, strftime\n",
    "\n",
    "neo_model_name=compilation_job_name + '-neo-model-latest'\n",
    "print(neo_model_name)\n",
    "\n",
    "info = client.describe_compilation_job(CompilationJobName=compilation_job_name)\n",
    "model_data = info['ModelArtifacts']['S3ModelArtifacts']\n",
    "print(model_data)\n",
    "\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "#TODO:Bug?? Forsome reason this returns 007439368137.dkr.ecr.us-east-2.amazonaws.com/xgboost-neo:1 and the endpoint fails with error image not found\n",
    "#neo_container = get_image_uri(region, 'xgboost-neo')\n",
    "neo_container = \"007439368137.dkr.ecr.us-east-2.amazonaws.com/xgboost-neo:latest\"\n",
    "\n",
    "primary_container = {\n",
    "    'Image': neo_container,\n",
    "    'ModelDataUrl': model_data\n",
    "}\n",
    "\n",
    "create_model_response = client.create_model(\n",
    "    ModelName = neo_model_name,\n",
    "    ExecutionRoleArn = role,\n",
    "    PrimaryContainer = primary_container)\n",
    "\n",
    "print(create_model_response['ModelArn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create endpoint configuration\n",
    "\n",
    "SageMaker supports configuring REST endpoints in hosting with multiple models, e.g. for A/B testing purposes. In order to support this, customers create an endpoint configuration, that describes the distribution of traffic across the models, whether split, shadowed, or sampled in some way. In addition, the endpoint configuration describes the instance type required for model deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_endpoint_config(endpoint_config_name, model_name):\n",
    "    from time import gmtime, strftime\n",
    "\n",
    "    #endpoint_config_name = 'DEMO-XGBoostEndpointConfig-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "    print(endpoint_config_name)\n",
    "    create_endpoint_config_response = client.create_endpoint_config(\n",
    "        EndpointConfigName = endpoint_config_name,\n",
    "        ProductionVariants=[{\n",
    "            'InstanceType':'ml.m4.xlarge',\n",
    "            'InitialVariantWeight':1,\n",
    "            'InitialInstanceCount':1,\n",
    "            'ModelName':model_name,\n",
    "            'VariantName':'AllTraffic'}])\n",
    "\n",
    "    print(\"Endpoint Config Arn: \" + create_endpoint_config_response['EndpointConfigArn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create endpoint\n",
    "Lastly, the customer creates the endpoint that serves up the model, through specifying the name and configuration defined above. The end result is an endpoint that can be validated and incorporated into production applications. This takes 9-11 minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1e+03 ns, total: 4 µs\n",
      "Wall time: 6.2 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import time\n",
    "\n",
    "def create_endpoint(endpoint_config_name, endpoint_name):\n",
    "#endpoint_name = 'DEMO-XGBoostEndpoint-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "    print(endpoint_name)\n",
    "    create_endpoint_response = client.create_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        EndpointConfigName=endpoint_config_name)\n",
    "    print(create_endpoint_response['EndpointArn'])\n",
    "\n",
    "    resp = client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = resp['EndpointStatus']\n",
    "    print(\"Status: \" + status)\n",
    "\n",
    "    while status=='Creating':\n",
    "        time.sleep(60)\n",
    "        resp = client.describe_endpoint(EndpointName=endpoint_name)\n",
    "        status = resp['EndpointStatus']\n",
    "        print(\"Status: \" + status)\n",
    "\n",
    "    print(\"Arn: \" + resp['EndpointArn'])\n",
    "    print(\"Status: \" + status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create neo endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "neo_endpoint_config_name = \"Neo-XHBoost-Sample-config-latest\"\n",
    "neo_endpoint_name = \"Neo-XHBoost-Sample-latest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neo-XHBoost-Sample-config-latest\n",
      "Endpoint Config Arn: arn:aws:sagemaker:us-east-2:324346001917:endpoint-config/neo-xhboost-sample-config-latest\n"
     ]
    }
   ],
   "source": [
    "create_endpoint_config (neo_endpoint_config_name, neo_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neo-XHBoost-Sample-latest\n",
      "arn:aws:sagemaker:us-east-2:324346001917:endpoint/neo-xhboost-sample-latest\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: InService\n",
      "Arn: arn:aws:sagemaker:us-east-2:324346001917:endpoint/neo-xhboost-sample-latest\n",
      "Status: InService\n"
     ]
    }
   ],
   "source": [
    "create_endpoint(neo_endpoint_config_name, neo_endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create normal endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_config_name = \"XHBoost-Sample-config\"\n",
    "endpoint_name = \"XHBoost-Sample\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XHBoost-Sample-config\n",
      "Endpoint Config Arn: arn:aws:sagemaker:us-east-2:324346001917:endpoint-config/xhboost-sample-config\n"
     ]
    }
   ],
   "source": [
    "create_endpoint_config (endpoint_config_name, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XHBoost-Sample\n",
      "arn:aws:sagemaker:us-east-2:324346001917:endpoint/xhboost-sample\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: InService\n",
      "Arn: arn:aws:sagemaker:us-east-2:324346001917:endpoint/xhboost-sample\n",
      "Status: InService\n"
     ]
    }
   ],
   "source": [
    "create_endpoint(endpoint_config_name, endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate the model for use\n",
    "Finally, the customer can now validate the model for use. They can obtain the endpoint from the client library using the result from previous operations, and generate classifications from the trained model using that endpoint.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_client = boto3.client('runtime.sagemaker', region_name=region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with a single prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -1 abalone.test > abalone.single.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  9 \n",
      "Prediction:  10\n",
      "CPU times: user 11 ms, sys: 841 µs, total: 11.8 ms\n",
      "Wall time: 169 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import json\n",
    "from itertools import islice\n",
    "import math\n",
    "import struct\n",
    "\n",
    "file_name = 'abalone.single.test' #customize to your test file\n",
    "with open(file_name, 'r') as f:\n",
    "    payload = f.read().strip()\n",
    "response = runtime_client.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                                   ContentType='text/x-libsvm', \n",
    "                                   Body=payload)\n",
    "result = response['Body'].read()\n",
    "result = result.decode(\"utf-8\")\n",
    "result = result.split(',')\n",
    "result = [math.ceil(float(i)) for i in result]\n",
    "label = payload.strip(' ').split()[0]\n",
    "print ('Label: ',label,'\\nPrediction: ', result[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoke normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.8 ms ± 3.35 ms per loop (mean ± std. dev. of 100 runs, 50 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n50 -r100\n",
    "response = runtime_client.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                                   ContentType='text/x-libsvm', \n",
    "                                   Body=payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoke neo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.3 ms ± 2.05 ms per loop (mean ± std. dev. of 100 runs, 50 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n50 -r100\n",
    "response = runtime_client.invoke_endpoint(EndpointName=neo_endpoint_name, \n",
    "                                   ContentType='text/x-libsvm', \n",
    "                                   Body=payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, a single prediction works. Let's do a whole batch to see how good is the predictions accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "def do_predict(data, endpoint_name, content_type):\n",
    "    payload = '\\n'.join(data)\n",
    "    response = runtime_client.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                                   ContentType=content_type, \n",
    "                                   Body=payload)\n",
    "    result = response['Body'].read()\n",
    "    result = result.decode(\"utf-8\")\n",
    "    result = result.split(',')\n",
    "    preds = [float((num)) for num in result]\n",
    "    preds = [math.ceil(num) for num in preds]\n",
    "    return preds\n",
    "\n",
    "def batch_predict(data, batch_size, endpoint_name, content_type):\n",
    "    items = len(data)\n",
    "    arrs = []\n",
    "    \n",
    "    for offset in range(0, items, batch_size):\n",
    "        if offset+batch_size < items:\n",
    "            results = do_predict(data[offset:(offset+batch_size)], endpoint_name, content_type)\n",
    "            arrs.extend(results)\n",
    "        else:\n",
    "            arrs.extend(do_predict(data[offset:items], endpoint_name, content_type))\n",
    "        sys.stdout.write('.')\n",
    "    return(arrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following helps us calculate the Median Absolute Percent Error (MdAPE) on the batch dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "with open(FILE_TEST, 'r') as f:\n",
    "    payload = f.read().strip()\n",
    "\n",
    "labels = [int(line.split(' ')[0]) for line in payload.split('\\n')]\n",
    "test_data = [line for line in payload.split('\\n')]\n",
    "preds = batch_predict(test_data, 100, endpoint_name, 'text/x-libsvm')\n",
    "\n",
    "print('\\n Median Absolute Percent Error (MdAPE) = ', np.median(np.abs(np.array(labels) - np.array(preds)) / np.array(labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete Endpoint\n",
    "Once you are done using the endpoint, you can use the following to delete it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_endpoint(EndpointName=endpoint_name)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
